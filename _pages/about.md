---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<blockquote cite="https://www.cmu.edu/about/today-we-work/index.html">
  <p>Today, we work.</p>
  <footer> - Carnegie Mellon University</footer>
</blockquote>

<!--- 
<b>On a hunt for full-time machine learning and software engineering roles for <u>January 2024</u>, where I can contribute intellectually to solve challenging problems :) !!!</b>
-->


ðŸ‘‹ Hello there! I am Soham (so-hum). Pleased to meet you! 

I am a graduate student at the Language Technologies Institute (LTI), Carnegie Mellon University. My master's focuses on machine learning (ML) and natural language processing (NLP).

My research interests lie in Large Language Models, Multimodal Machine Learning, Audio-based interactions, and Natural Language Processing. I am passionate about research involving the theoretical and applied study of Deep Learning and Natural Language Processing. My research has been presented at conferences like ACL,  ISLS, APSIPA, and NeurIPS. 

My efforts at CMU have been focused on various aspects of interactive intelligence. Be it my current capstone, where I am working towards an on-device multimodal,  virtual teaching assistant, or the courses I took like Artificial Social Intelligence, where I actively participated in discussions on realizing social intelligence in AI. 

On the other hand, I am also working towards enhancing my breadth by taking courses like Deep Reinforcement Learning and learning about Large Language Models (LLMs). 

My internship project at ï£¿ Apple was also part of an effort to investigate how to run LLMs on a device. I built a Jax-based online-model distillation framework for distilling LLMs on distributed GPUs. In the process, I learned and tackled how to optimize memory and shard models to enable fitting the teacher and student models into the GPU. I also identified limitations of the famous [TinyBERT](https://arxiv.org/abs/1909.10351) distillation algorithm for decoder-style LLMs.

My experiences in Machine learning, Deep Learning, Reinforcement Learning, Speech and Audio Processing, and NLP have enabled me to apply my learnings when researching and building distributed frameworks. 

My current aim is to maximize my learning to enhance my depth and breadth and use the knowledge to research and develop applications that deliver pleasant end-user experiences.

My drive to keep on learning and appreciation of the importance of teamwork and collaborative progress will help me achieve my goal of creating meaningful technology that makes everyone's lives better :sunny:. 


<blockquote cite="https://www.cmu.edu/about/today-we-work/index.html">
  <p>Happiness can be found, even in the darkest of times, if one only remembers to turn on the light.</p>
  <footer> - Albus Dumbledore, created by J. K. Rowling</footer>
</blockquote>